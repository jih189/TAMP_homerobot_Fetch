{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ac0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "from door_opener.srv import HandleDetection\n",
    "from visualization_msgs.msg import Marker\n",
    "from ros_tensorflow_msgs.srv import *\n",
    "from sensor_msgs.msg import PointCloud, PointCloud2, PointField\n",
    "from sensor_msgs import point_cloud2 as pc2\n",
    "from manipulation_test.srv import *\n",
    "import tf2_ros\n",
    "import numpy as np\n",
    "import tf.transformations as tf_trans\n",
    "from geometry_msgs.msg import Pose, Point, Quaternion, PoseStamped\n",
    "\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "from moveit_msgs.msg import RobotState\n",
    "from sensor_msgs.msg import JointState\n",
    "from moveit_msgs.msg import AttachedCollisionObject\n",
    "from moveit_msgs.msg import CollisionObject\n",
    "\n",
    "import actionlib\n",
    "from control_msgs.msg import (\n",
    "    FollowJointTrajectoryAction,\n",
    "    FollowJointTrajectoryGoal,\n",
    "    GripperCommandAction,\n",
    "    GripperCommandGoal,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013762a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pointcloud_to_pointcloud2(pc):\n",
    "    '''\n",
    "    Converts a ROS PointCloud message to a ROS PointCloud2 message.\n",
    "    \n",
    "    :param pc: a ROS PointCloud message\n",
    "    :type pc: PointCloud\n",
    "    :returns: a ROS PointCloud2 message\n",
    "    :rtype: PointCloud2\n",
    "    '''\n",
    "\n",
    "    # Create a list of 3-tuples where each tuple is (x, y, z)\n",
    "    pc2_data = [(p.x, p.y, p.z) for p in pc.points]\n",
    "\n",
    "    # Create header\n",
    "    header = pc.header\n",
    "\n",
    "    # Create a PointCloud2 message\n",
    "    pc2_msg = pc2.create_cloud_xyz32(header, pc2_data)\n",
    "\n",
    "    return pc2_msg\n",
    "\n",
    "def pointcloud_to_numpy(point_cloud):\n",
    "    points = []\n",
    "\n",
    "    for point in point_cloud.points:\n",
    "        points.append([point.x, point.y, point.z])\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "def numpy_to_pointcloud2(points):\n",
    "    \"\"\"\n",
    "    Converts a numpy array to a sensor_msgs/PointCloud2 message.\n",
    "\n",
    "    :param points: Numpy array of point cloud\n",
    "    :type points: numpy.ndarray\n",
    "    :returns: sensor_msgs/PointCloud2 message\n",
    "    :rtype: PointCloud2\n",
    "    \"\"\"\n",
    "    # Create a list of PointField\n",
    "    fields = [PointField('x', 0, PointField.FLOAT32, 1),\n",
    "              PointField('y', 4, PointField.FLOAT32, 1),\n",
    "              PointField('z', 8, PointField.FLOAT32, 1)]\n",
    "\n",
    "    # Create a header\n",
    "    header = std_msgs.msg.Header()\n",
    "    header.stamp = rospy.Time.now()\n",
    "    header.frame_id = 'base_link'  # replace with your frame id\n",
    "\n",
    "    # Convert the points array to PointCloud2\n",
    "    point_cloud2 = pc2.create_cloud(header, fields, points)\n",
    "\n",
    "    return point_cloud2\n",
    "\n",
    "def get_rotation_matrix(direction):\n",
    "    \"\"\"\n",
    "    Computes the rotation matrix that will align the given direction vector with the up vector [0, 0, 1].\n",
    "\n",
    "    :param direction: 3D direction vector\n",
    "    :type direction: numpy.ndarray\n",
    "    :return: 3x3 rotation matrix\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # Normalize the direction vector\n",
    "    direction = direction / np.linalg.norm(direction)\n",
    "\n",
    "    # Define the up vector\n",
    "    up = np.array([0, 0, 1])\n",
    "\n",
    "    # Compute the rotation axis via the cross product\n",
    "    axis = np.cross(direction, up)\n",
    "    axis = axis / np.linalg.norm(axis)\n",
    "\n",
    "    # Compute the rotation angle via the dot product\n",
    "    angle = np.arccos(np.dot(direction, up))\n",
    "\n",
    "    # Compute the rotation matrix using the axis-angle formula\n",
    "    K = np.array([[0, -axis[2], axis[1]],\n",
    "                  [axis[2], 0, -axis[0]],\n",
    "                  [-axis[1], axis[0], 0]])\n",
    "\n",
    "    rotation_matrix = np.eye(4)\n",
    "    rotation_matrix[:3, :3] = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * np.dot(K, K)\n",
    "    return rotation_matrix\n",
    "\n",
    "def pose_to_matrix(pose):\n",
    "    \"\"\"\n",
    "    Converts a geometry_msgs/Pose message to a 4x4 transformation matrix.\n",
    "\n",
    "    :param pose: A geometry_msgs/Pose message\n",
    "    :type pose: Pose\n",
    "    :return: 4x4 transformation matrix\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # Extract the translation\n",
    "    translation = np.array([pose.position.x, pose.position.y, pose.position.z])\n",
    "\n",
    "    # Extract the rotation (as a quaternion)\n",
    "    quaternion = np.array([pose.orientation.x, pose.orientation.y, pose.orientation.z, pose.orientation.w])\n",
    "\n",
    "    # Convert the quaternion to a 3x3 rotation matrix\n",
    "    rotation_matrix = tf_trans.quaternion_matrix(quaternion)\n",
    "\n",
    "    # Create a 4x4 transformation matrix\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix[:3, :3]\n",
    "    transformation_matrix[:3, 3] = translation\n",
    "\n",
    "    return transformation_matrix\n",
    "\n",
    "def matrix_to_pose(matrix):\n",
    "    \"\"\"\n",
    "    Converts a 4x4 transformation matrix to a geometry_msgs/Pose message.\n",
    "\n",
    "    :param matrix: 4x4 transformation matrix\n",
    "    :type matrix: numpy.ndarray\n",
    "    :return: A geometry_msgs/Pose message\n",
    "    :rtype: Pose\n",
    "    \"\"\"\n",
    "    # Extract the translation\n",
    "    translation = matrix[:3, 3]\n",
    "\n",
    "    #     # Extract the rotation (as a 3x3 matrix)\n",
    "    #     rotation_matrix = matrix[:3, :3]\n",
    "\n",
    "    # Convert the rotation matrix to a quaternion\n",
    "    quaternion = tf_trans.quaternion_from_matrix(matrix)\n",
    "\n",
    "    # Create a Pose message\n",
    "    pose = Pose()\n",
    "    pose.position = Point(*translation)\n",
    "    pose.orientation = Quaternion(*quaternion)\n",
    "\n",
    "    return pose\n",
    "\n",
    "def pose_on_plane_close_to_origin(plane):\n",
    "    \"\"\"\n",
    "    Computes a pose on the plane, with the position being the point on the plane closest to the origin.\n",
    "\n",
    "    :param plane: The coefficients [A, B, C, D] of the plane equation Ax + By + Cz + D = 0\n",
    "    :type plane: numpy.ndarray\n",
    "    :return: The pose on the plane\n",
    "    :rtype: Pose\n",
    "    \"\"\"\n",
    "    # Extract the normal vector and distance from the plane parameters\n",
    "    normal = plane[:3]\n",
    "    d = plane[3]\n",
    "\n",
    "    # Normalize the normal vector\n",
    "    normal = normal / np.linalg.norm(normal)\n",
    "\n",
    "    # Choose the point on the plane closest to the origin for the position\n",
    "    position = -d / np.dot(normal, normal) * normal\n",
    "\n",
    "    # Choose a vector orthogonal to the normal vector as the X-axis\n",
    "    if normal[0] != 0:\n",
    "        x_axis = np.array([normal[1], -normal[0], 0])\n",
    "    elif normal[1] != 0:\n",
    "        x_axis = np.array([-normal[1], normal[0], 0])\n",
    "    else:  # normal[2] != 0\n",
    "        x_axis = np.array([0, -normal[2], normal[1]])\n",
    "\n",
    "    # Normalize the X-axis vector\n",
    "    x_axis = x_axis / np.linalg.norm(x_axis)\n",
    "\n",
    "    # Compute the Y-axis vector as the cross product of the normal and X-axis vectors\n",
    "    y_axis = np.cross(normal, x_axis)\n",
    "\n",
    "    # Construct a rotation matrix from the axes\n",
    "    rotation_matrix = np.eye(4)\n",
    "    rotation_matrix[:3, :3] = np.vstack((x_axis, y_axis, normal)).T\n",
    "\n",
    "    # Convert the rotation matrix to a quaternion\n",
    "    orientation = tf_trans.quaternion_from_matrix(rotation_matrix)\n",
    "\n",
    "    # Return the pose\n",
    "    return Pose(position=Point(*position), orientation=Quaternion(*orientation))\n",
    "\n",
    "#open gripper\n",
    "def open_gripper(gripper_client):\n",
    "    goal = GripperCommandGoal()\n",
    "    goal.command.position = float(0.08)\n",
    "    goal.command.max_effort = 100\n",
    "    gripper_client.send_goal_and_wait(goal)\n",
    "\n",
    "# close gripper\n",
    "def close_gripper(gripper_client):\n",
    "    goal = GripperCommandGoal()\n",
    "    goal.command.position = float(0.0)\n",
    "    goal.command.max_effort = 100\n",
    "    gripper_client.send_goal_and_wait(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('handle_detection_client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bda11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveit_commander.roscpp_initialize(sys.argv)\n",
    "move_group = moveit_commander.MoveGroupCommander(\"arm\") \n",
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "# move_group.set_max_velocity_scaling_factor(1.0)\n",
    "\n",
    "gripper_client = actionlib.SimpleActionClient(\n",
    "                \"/gripper_controller/gripper_action\", GripperCommandAction\n",
    "            )\n",
    "gripper_client.wait_for_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceed3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.wait_for_service('handle_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662117c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get camera transform from tf tree\n",
    "tfBuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    camera_trans = tfBuffer.lookup_transform('base_link', 'head_camera_rgb_optical_frame', rospy.Time())\n",
    "except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):\n",
    "    print(\"tf error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccfca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a service proxy\n",
    "handle_detection_service = rospy.ServiceProxy('handle_detection', HandleDetection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb93529",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = handle_detection_service(camera_trans)\n",
    "print 'get ', len(res.handle_motions), ' handles from camera'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add table into the planning scene\n",
    "drawer_pose_stamped = geometry_msgs.msg.PoseStamped()\n",
    "drawer_pose_stamped.header.frame_id = \"base_link\"\n",
    "# drawer_pose_stamped.pose = pose_on_plane_close_to_origin(coef_test)\n",
    "drawer_pose_stamped.pose = pose_on_plane_close_to_origin(np.array(res.handle_motions[0].drawer_plane.coef))\n",
    "drawer_name = \"drawer\"\n",
    "scene.add_box(drawer_name, drawer_pose_stamped, size=(2.0, 2.0, 0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd90c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker_pub = rospy.Publisher(\"/visualization_marker\", Marker, queue_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ffb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker_list = []\n",
    "# marker_id_temp = 0\n",
    "# for handle_motion in res.handle_motions:\n",
    "#     marker = Marker()\n",
    "\n",
    "#     marker.header.frame_id = \"base_link\"\n",
    "#     marker.header.stamp = rospy.Time.now()\n",
    "\n",
    "#     # set shape, Arrow: 0; Cube: 1 ; Sphere: 2 ; Cylinder: 3\n",
    "#     marker.type = 2\n",
    "#     marker.id = marker_id_temp\n",
    "\n",
    "#     # Set the scale of the marker\n",
    "#     marker.scale.x = 0.05\n",
    "#     marker.scale.y = 0.05\n",
    "#     marker.scale.z = 0.05\n",
    "\n",
    "#     # Set the color\n",
    "#     marker.color.r = 0.0\n",
    "#     marker.color.g = 1.0\n",
    "#     marker.color.b = 0.0\n",
    "#     marker.color.a = 1.0\n",
    "\n",
    "#     # Set the pose of the marker\n",
    "#     marker.pose.position.x = handle_motion.handle_direction[0]\n",
    "#     marker.pose.position.y = handle_motion.handle_direction[1]\n",
    "#     marker.pose.position.z = handle_motion.handle_direction[2]\n",
    "#     marker.pose.orientation.x = 0.0\n",
    "#     marker.pose.orientation.y = 0.0\n",
    "#     marker.pose.orientation.z = 0.0\n",
    "#     marker.pose.orientation.w = 1.0\n",
    "    \n",
    "#     marker_list.append(marker)\n",
    "#     marker_id_temp += 1\n",
    "    \n",
    "#     arrow_marker = Marker()\n",
    "#     arrow_marker.header.frame_id = \"base_link\"\n",
    "#     arrow_marker.header.stamp = rospy.Time.now()\n",
    "\n",
    "#     # set shape, Arrow: 0; Cube: 1 ; Sphere: 2 ; Cylinder: 3\n",
    "#     arrow_marker.type = 0\n",
    "#     arrow_marker.id = marker_id_temp\n",
    "\n",
    "#     # Set the scale of the marker\n",
    "#     arrow_marker.scale.x = 0.01\n",
    "#     arrow_marker.scale.y = 0.01\n",
    "#     arrow_marker.scale.z = 0.01\n",
    "\n",
    "#     # Set the color\n",
    "#     arrow_marker.color.r = 1.0\n",
    "#     arrow_marker.color.g = 0.0\n",
    "#     arrow_marker.color.b = 0.0\n",
    "#     arrow_marker.color.a = 1.0\n",
    "    \n",
    "#     start = Point(handle_motion.handle_direction[0], handle_motion.handle_direction[1], handle_motion.handle_direction[2])\n",
    "#     end = Point(handle_motion.handle_direction[0] + handle_motion.handle_direction[3] * 0.3, \n",
    "#                 handle_motion.handle_direction[1] + handle_motion.handle_direction[4] * 0.3, \n",
    "#                 handle_motion.handle_direction[2] + handle_motion.handle_direction[5] * 0.3)\n",
    "\n",
    "#     arrow_marker.points = [start, end]\n",
    "    \n",
    "#     marker_list.append(arrow_marker)\n",
    "#     marker_id_temp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80937809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # publish the marker for visualization\n",
    "# while not rospy.is_shutdown():\n",
    "#     for m in marker_list:\n",
    "#         marker_pub.publish(m)\n",
    "#     rospy.rostime.wallsleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f2758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.wait_for_service('grasp_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_predictor = rospy.ServiceProxy('grasp_predict', Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, we select the first handle to open the drawer.\n",
    "handle_pointcloud_numpy = pointcloud_to_numpy(res.handle_motions[0].handle_pc)\n",
    "\n",
    "plane_numpy = np.array(res.handle_motions[0].drawer_plane.coef)\n",
    "open_rotate_mat = get_rotation_matrix(np.array([res.handle_motions[0].handle_direction[3], \n",
    "                                           res.handle_motions[0].handle_direction[4], \n",
    "                                           res.handle_motions[0].handle_direction[5]]))\n",
    "rotated_handle_pointcloud_numpy = np.dot(open_rotate_mat, \n",
    "                                         np.hstack((handle_pointcloud_numpy, \n",
    "                                                    np.ones((handle_pointcloud_numpy.shape[0], 1)))).T).T[:, :3]\n",
    "try:\n",
    "    predicted_grasp_result = grasp_predictor(numpy_to_pointcloud2(rotated_handle_pointcloud_numpy), \n",
    "                                             numpy_to_pointcloud2(rotated_handle_pointcloud_numpy), \n",
    "                                             camera_trans)\n",
    "except rospy.ServiceException as e:\n",
    "    print(\"Service call failed: %s\"%e)\n",
    "    \n",
    "filtered_grasp_poses_for_vis = []\n",
    "filtered_grasp_poses = []\n",
    "\n",
    "\n",
    "for i in range(len(predicted_grasp_result.predicted_grasp_poses)):\n",
    "    grasp_pose_mat = pose_to_matrix(predicted_grasp_result.predicted_grasp_poses[i].pose)\n",
    "    # need to filter the grasp pose which may hit the drawer.\n",
    "    collision_detect_mat = np.dot(np.linalg.inv(open_rotate_mat), grasp_pose_mat)\n",
    "    \n",
    "    finger1_collision_detect_mat = np.dot(collision_detect_mat, np.array([0.12,0.4,0,1]))\n",
    "    finger2_collision_detect_mat = np.dot(collision_detect_mat, np.array([0.12,-0.4,0,1]))\n",
    "    \n",
    "    c1 = np.dot(plane_numpy[:3], collision_detect_mat[:3, 3]) + plane_numpy[3] > 0\n",
    "    c2 = np.dot(plane_numpy[:3], finger1_collision_detect_mat[:3]) + plane_numpy[3] > 0\n",
    "    c3 = np.dot(plane_numpy[:3], finger2_collision_detect_mat[:3]) + plane_numpy[3] > 0\n",
    "    \n",
    "    if (c1 and c2 and c3) or (not (c1 or c2 or c3)):\n",
    "        grasp_pose_stamped = PoseStamped()\n",
    "        grasp_pose_stamped.header.stamp = rospy.Time.now()\n",
    "        filtered_grasp_pose_mat = np.dot(np.linalg.inv(open_rotate_mat), grasp_pose_mat)\n",
    "        filtered_grasp_poses.append(filtered_grasp_pose_mat)\n",
    "        grasp_pose_stamped.pose= matrix_to_pose(filtered_grasp_pose_mat)\n",
    "        filtered_grasp_poses_for_vis.append(grasp_pose_stamped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a760068",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.wait_for_service('visualize_regrasp')\n",
    "grasp_visualizer = rospy.ServiceProxy('visualize_regrasp', VisualizeRegrasp)\n",
    "grasp_visualizer(filtered_grasp_poses_for_vis, \n",
    "                 [0.08 for _ in range(len(filtered_grasp_poses_for_vis))], \n",
    "                 [0 for _ in range(len(filtered_grasp_poses_for_vis))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1397820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from ros_numpy import numpify, msgify\n",
    "import tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_trajectory_publisher = rospy.Publisher(\n",
    "            \"/move_group/display_planned_path\",\n",
    "            moveit_msgs.msg.DisplayTrajectory,\n",
    "            queue_size=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb240c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open gripper\n",
    "open_gripper(gripper_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a242572",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_shift = np.array([[1,0,0,0.02],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "pre_grasp_shift = np.array([[1,0,0,-0.1],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "\n",
    "pre_grasp_pose = np.eye(4)\n",
    "grasp_pose = np.eye(4)\n",
    "open_drawer_pose = np.eye(4)\n",
    "# need to plan the motion to pre-grasp pose.\n",
    "random.shuffle(filtered_grasp_poses)\n",
    "for g in filtered_grasp_poses[:5]:\n",
    "    move_group.set_start_state_to_current_state()\n",
    "    # generate grasp pose\n",
    "    grasp_pose = g.dot(grasp_shift)\n",
    "\n",
    "    # calculate the pre-grasp pose\n",
    "    pre_grasp_pose = grasp_pose.dot(pre_grasp_shift)\n",
    "    \n",
    "    # pose to move it for opening the drawer\n",
    "    open_drawer_pose = grasp_pose.copy()\n",
    "    open_drawer_pose[0,3] += res.handle_motions[0].handle_direction[3] * 0.1\n",
    "    open_drawer_pose[1,3] += res.handle_motions[0].handle_direction[4] * 0.1\n",
    "    open_drawer_pose[2,3] += res.handle_motions[0].handle_direction[5] * 0.1\n",
    "    \n",
    "    trans = tf.transformations.translation_from_matrix(pre_grasp_pose).tolist()\n",
    "    quat = tf.transformations.quaternion_from_matrix(pre_grasp_pose).tolist()\n",
    "\n",
    "    move_group.clear_pose_targets()\n",
    "    move_group.set_pose_target(trans + quat)\n",
    "    plan_result = move_group.plan()\n",
    "    \n",
    "    if plan_result[0]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_trajectory = moveit_msgs.msg.DisplayTrajectory()\n",
    "display_trajectory.trajectory_start = move_group.get_current_state()\n",
    "display_trajectory.trajectory.append(plan_result[1])\n",
    "# display_trajectory.trajectory.append(opening_plan)\n",
    "# Publish\n",
    "display_trajectory_publisher.publish(display_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_group.execute(plan_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_group.set_start_state_to_current_state()\n",
    "(approach_plan, fraction) = move_group.compute_cartesian_path([msgify(geometry_msgs.msg.Pose, grasp_pose)], 0.01, 0.0)\n",
    "print fraction\n",
    "# check whether you can place the object\n",
    "if fraction > 0.9:\n",
    "    print \"good to go\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_trajectory = moveit_msgs.msg.DisplayTrajectory()\n",
    "display_trajectory.trajectory_start = move_group.get_current_state()\n",
    "display_trajectory.trajectory.append(approach_plan)\n",
    "# Publish\n",
    "display_trajectory_publisher.publish(display_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_group.execute(approach_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close gripper\n",
    "close_gripper(gripper_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_group.set_start_state_to_current_state()\n",
    "(opening_plan, fraction) = move_group.compute_cartesian_path([msgify(geometry_msgs.msg.Pose, open_drawer_pose)], 0.01, 0.0)\n",
    "print fraction\n",
    "# check whether you can place the object\n",
    "if fraction > 0.9:\n",
    "    print \"good to go\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_trajectory = moveit_msgs.msg.DisplayTrajectory()\n",
    "display_trajectory.trajectory_start = move_group.get_current_state()\n",
    "display_trajectory.trajectory.append(opening_plan)\n",
    "# Publish\n",
    "display_trajectory_publisher.publish(display_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_group.execute(opening_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open gripper\n",
    "open_gripper(gripper_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
