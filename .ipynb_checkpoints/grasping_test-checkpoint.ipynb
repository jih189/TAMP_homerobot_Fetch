{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0f65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "import tf2_ros\n",
    "from ros_tensorflow_msgs.srv import *\n",
    "from rail_segmentation.srv import *\n",
    "from rail_manipulation_msgs.srv import *\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "from manipulation_test.srv import *\n",
    "\n",
    "import tf\n",
    "from ros_numpy import numpify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9ec209",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('example_node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6cf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the table first\n",
    "rospy.wait_for_service('table_searcher/search_table')\n",
    "table_searcher = rospy.ServiceProxy('table_searcher/search_table', SearchTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4683063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = table_searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09cd2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect obstacle on the table\n",
    "rospy.wait_for_service('table_searcher/segment_objects')\n",
    "object_searcher = rospy.ServiceProxy('table_searcher/segment_objects', SegmentObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f18d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_objects = object_searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318773f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected objects' number:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"detected objects' number: \", len(detected_objects.segmented_objects.objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f86b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get camera transform from tf tree\n",
    "tfBuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616ac5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    camera_trans = tfBuffer.lookup_transform('base_link', 'head_camera_rgb_optical_frame', rospy.Time())\n",
    "except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):\n",
    "    print(\"tf error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61210350",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.wait_for_service('grasp_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e031eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_predictor = rospy.ServiceProxy('grasp_predict', Predict)\n",
    "try:\n",
    "    predicted_grasp_result = grasp_predictor(table_info.full_point_cloud, detected_objects.segmented_objects.objects[0].point_cloud, camera_trans)\n",
    "except rospy.ServiceException as e:\n",
    "    print(\"Service call failed: %s\"%e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e04128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the client to visualize the predicted grasp poses\n",
    "rospy.wait_for_service('visualize_regrasp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e479557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "\n",
    "def pose_to_vector(pose_stamped):\n",
    "    pos = pose_stamped.pose.position\n",
    "    quat = pose_stamped.pose.orientation\n",
    "\n",
    "    return np.array([pos.x, pos.y, pos.z, quat.x, quat.y, quat.z, quat.w])\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    return np.linalg.norm(v1 - v2)\n",
    "\n",
    "def k_means_clustering(poses, k, max_iterations=100):\n",
    "    # Convert poses to vectors\n",
    "    pose_vectors = [pose_to_vector(pose) for pose in poses]\n",
    "\n",
    "    # Randomly initialize centroids\n",
    "    centroids = random.sample(pose_vectors, k)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Assign pose_vectors to nearest centroids\n",
    "        clusters_indices = [[] for _ in range(k)]\n",
    "        for i, pose_vector in enumerate(pose_vectors):\n",
    "            closest_centroid_index = np.argmin([euclidean_distance(pose_vector, centroid) for centroid in centroids])\n",
    "            clusters_indices[closest_centroid_index].append(i)\n",
    "\n",
    "        # Update centroids\n",
    "        new_centroids = [np.mean([pose_vectors[i] for i in cluster], axis=0) for cluster in clusters_indices]\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    # Create clusters of PoseStamped objects\n",
    "    clusters = [[poses[i] for i in cluster] for cluster in clusters_indices]\n",
    "\n",
    "    return clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b9224c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_visualizer = rospy.ServiceProxy('visualize_regrasp', VisualizeRegrasp)\n",
    "try:\n",
    "    clustered_grasp_poses = k_means_clustering(predicted_grasp_result.predicted_grasp_poses, 10)\n",
    "    grasp_visualizer(clustered_grasp_poses, [0.08 for _ in range(10)], [0 for _ in range(10)])\n",
    "except rospy.ServiceException as e:\n",
    "    print(\"Service call failed: %s\"%e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6db3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensor_msgs.msg import CameraInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ed27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_info = rospy.wait_for_message('/head_camera/rgb/camera_info', CameraInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d6aa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_matrix = np.reshape(camera_info.K, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3785ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_3d_to_2d(point_3d, intrinsic_matrix):\n",
    "\n",
    "    # Project the 3D point to 2D using the intrinsic matrix\n",
    "    point_2d_homogeneous = np.dot(intrinsic_matrix, point_3d)\n",
    "\n",
    "    # Normalize the homogeneous 2D point to obtain the Euclidean 2D point\n",
    "    point_2d = point_2d_homogeneous / point_2d_homogeneous[2]\n",
    "\n",
    "    return point_2d[:2]\n",
    "\n",
    "def is_in_box(point_3d, intrinsic_matrix, min_x, max_x, min_y, max_y):\n",
    "    point_2d = project_3d_to_2d(point_3d, intrinsic_matrix)\n",
    "    u = point_2d[0]\n",
    "    v = point_2d[1]\n",
    "    if(u < min_x or u > max_x or v < min_y or v > max_y):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c625b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = [100, 300, 0, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b0f5270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in box\n"
     ]
    }
   ],
   "source": [
    "selected_id = 0\n",
    "has_selected_object = False\n",
    "for i in range(len(detected_objects.segmented_objects.objects)):\n",
    "    object_center = np.array([detected_objects.segmented_objects.objects[i].center.x, \n",
    "                              detected_objects.segmented_objects.objects[i].center.y, \n",
    "                              detected_objects.segmented_objects.objects[i].center.z])\n",
    "    object_center_in_cam = np.dot(np.linalg.inv(numpify(camera_trans.transform)), np.append(object_center, 1))[:3]\n",
    "    \n",
    "    if is_in_box(object_center_in_cam, camera_matrix, boundary[0], boundary[1], boundary[2], boundary[3]):\n",
    "        selected_id = i\n",
    "        has_selected_object = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fcd00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
